{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "import smtplib\n",
    "import platform\n",
    "import requests\n",
    "import joblib\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from email.message import EmailMessage\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from rich import print\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.progress import track\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "import openai\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Email configuration\n",
    "SMTP_SERVER =  \"...\"\n",
    "SMTP_PORT = ...\n",
    "EMAIL_SENDER =  \"...\"\n",
    "EMAIL_PASSWORD =  \"...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REALIZAR_SCRAPING = True  # Change to False to avoid scraping\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Detect the operating system and set the appropriate User-Agent\n",
    "system = platform.system()\n",
    "if system == \"Windows\":\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\"\n",
    "elif system == \"Darwin\":  # macOS\n",
    "    user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\"\n",
    "else:  # Linux or others\n",
    "    user_agent = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\"\n",
    "\n",
    "# Function to start a new browser\n",
    "def iniciar_navegador():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "    options.headless = False  # or True if you don‚Äôt want the browser to be visible\n",
    "    # üîß Key line: prevents zombie process errors\n",
    "    return uc.Chrome(options=options, use_subprocess=True)\n",
    "\n",
    "# Function to safely restart the browser\n",
    "def reiniciar_navegador():\n",
    "    global browser\n",
    "    try:\n",
    "        browser.quit()\n",
    "    except Exception as e:\n",
    "        console.print(f\"[yellow]‚ö†Ô∏è Could not close the browser normally:[/yellow] {e}\")\n",
    "    time.sleep(5)  # Allow time to close properly\n",
    "    browser = iniciar_navegador()\n",
    "\n",
    "# Start browser\n",
    "browser = iniciar_navegador()\n",
    "\n",
    "# CSV file paths\n",
    "ids_csv_path = '../data/ids_casas.csv'\n",
    "casas_csv_path = '../data/casas_idealista.csv'\n",
    "\n",
    "# Load existing IDs\n",
    "ids_existentes = set()\n",
    "try:\n",
    "    ids_existentes = set(pd.read_csv(ids_csv_path)['id'].dropna().astype(str).tolist())\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "pagina = 1\n",
    "nuevos_ids = []\n",
    "repetidos_consecutivos = 0\n",
    "limite_repetidos = 5\n",
    "\n",
    "try:\n",
    "    while REALIZAR_SCRAPING:\n",
    "        url = f'https://www.idealista.com/venta-viviendas/zaragoza-zaragoza/pagina-{pagina}.htm?ordenado-por=fecha-publicacion-desc'\n",
    "        console.print(f\"\\n[bold cyan]üåç Accessing page:[/bold cyan] {pagina}\")\n",
    "\n",
    "        try:\n",
    "            browser.get(url)\n",
    "            browser.delete_all_cookies()\n",
    "            time.sleep(random.uniform(8, 15))\n",
    "        except Exception as e:\n",
    "            console.print(f\"[bold red]‚ö†Ô∏è Error accessing page {pagina}:[/bold red] {e}\")\n",
    "            reiniciar_navegador()\n",
    "            continue\n",
    "\n",
    "        # Try to close the cookies notice\n",
    "        try:\n",
    "            browser.find_element(\"xpath\", '//*[@id=\"didomi-notice-agree-button\"]').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        soup = bs(browser.page_source, 'lxml')\n",
    "        articles = soup.find('main', {'class': 'listing-items'}).find_all('article')\n",
    "\n",
    "        console.print(f\"[bold green]üè° Number of properties found:[/bold green] {len(articles)}\")\n",
    "\n",
    "        for article in track(articles, description=\"üì• Processing properties...\"):\n",
    "            id_muebles = article.get('data-element-id')\n",
    "\n",
    "            if id_muebles:\n",
    "                if str(id_muebles) in ids_existentes:\n",
    "                    repetidos_consecutivos += 1\n",
    "                    console.print(f\"üîÅ [yellow]Duplicate ID found:[/yellow] {id_muebles} (Total consecutive duplicates: {repetidos_consecutivos})\")\n",
    "\n",
    "                    if repetidos_consecutivos >= limite_repetidos:\n",
    "                        raise StopIteration  # Stop if too many consecutive duplicates\n",
    "\n",
    "                    continue\n",
    "\n",
    "                repetidos_consecutivos = 0\n",
    "                nuevos_ids.append(id_muebles)\n",
    "\n",
    "        pagina += 1\n",
    "        time.sleep(random.uniform(5, 10))\n",
    "\n",
    "except StopIteration:\n",
    "    console.print(\"\\n[bold red]üö® Scraping stopped due to multiple consecutive duplicates.[/bold red]\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    console.print(\"\\n[bold red]üõë Scraping manually interrupted.[/bold red]\")\n",
    "\n",
    "finally:\n",
    "    df_nuevas_casas = pd.DataFrame()\n",
    "    i = 0\n",
    "\n",
    "    while i < len(nuevos_ids):\n",
    "        nuevo_id = nuevos_ids[i]\n",
    "        console.print(f\"üìå [cyan]Processing data for ID:[/cyan] {nuevo_id}\")\n",
    "\n",
    "        try:\n",
    "            url = f\"https://www.idealista.com/inmueble/{nuevo_id}/\"\n",
    "\n",
    "            intentos = 0\n",
    "            max_intentos = 2\n",
    "            titulo = None\n",
    "\n",
    "            while intentos < max_intentos and not titulo:\n",
    "                try:\n",
    "                    browser.get(url)\n",
    "                    time.sleep(random.uniform(4, 6))\n",
    "                    html = browser.page_source\n",
    "                    soup = bs(html, 'lxml')\n",
    "\n",
    "                    # Look for title to confirm the page loaded correctly\n",
    "                    titulo = soup.find('span', {'class': 'main-info__title-main'})\n",
    "\n",
    "                    if not titulo:\n",
    "                        raise Exception(\"Property title not found.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    intentos += 1\n",
    "                    console.print(f\"üîÅ [yellow]Attempt {intentos}/{max_intentos} failed for property {nuevo_id}:[/yellow] {e}\")\n",
    "\n",
    "                    if intentos == 1:\n",
    "                        console.print(\"[bold yellow]üõë Enable VPN or change IP, then press Enter to continue...[/bold yellow]\")\n",
    "                        input(\"‚ñ∂Ô∏è Press Enter when ready: \")\n",
    "                        reiniciar_navegador()\n",
    "\n",
    "            if not titulo:\n",
    "                console.print(f\"‚ö†Ô∏è [red]Property {nuevo_id} not available. It may have been removed or you are still blocked.[/red]\")\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            titulo = soup.find('span', {'class': 'main-info__title-main'})\n",
    "            localizacion = soup.find('span', {'class': 'main-info__title-minor'})\n",
    "            precio_tag = soup.find('span', {'class': 'txt-bold'})\n",
    "            c1 = soup.find('div', {'class': 'details-property-feature-one'})\n",
    "            c2 = soup.find('div', {'class': 'details-property-feature-two'})\n",
    "\n",
    "            casas = {\n",
    "                'id': nuevo_id,\n",
    "                'Titulo': titulo.text if titulo else None,\n",
    "                'Localizacion': localizacion.text.split(',')[0] if localizacion else None,\n",
    "                'Precio': int(precio_tag.text.replace('.', '').replace('‚Ç¨', '').strip()) if precio_tag else None,\n",
    "                'Caracteristicas_basicas': '; '.join([caract.text.strip() for caract in c1.find_all('li')]) if c1 else None,\n",
    "                'Caracteristicas_extra': '; '.join([caract.text.strip() for caract in c2.find_all('li')]) if c2 else None\n",
    "            }\n",
    "\n",
    "            df_casas = pd.DataFrame([casas])\n",
    "            df_nuevas_casas = pd.concat([df_nuevas_casas, df_casas], ignore_index=True)\n",
    "            i += 1  # Only move forward if successful\n",
    "\n",
    "        except Exception as e:\n",
    "            console.print(f\"‚ùå [red]Error processing property {nuevo_id}:[/red] {e}\")\n",
    "            i += 1  # Or use `continue` if you want to retry later\n",
    "\n",
    "    browser.quit()\n",
    "\n",
    "    if not df_nuevas_casas.empty:\n",
    "        df_nuevas_casas.to_csv(casas_csv_path, index=False, sep=';', encoding='utf-16')\n",
    "        console.print(f\"\\nüíæ [green]Data for {len(df_nuevas_casas)} properties saved to:[/green] {casas_csv_path}\")\n",
    "\n",
    "        try:\n",
    "            df_ids_nuevos = pd.DataFrame(df_nuevas_casas['id'], columns=['id'])\n",
    "            df_ids_nuevos.to_csv(ids_csv_path, mode='a', header=False, index=False)\n",
    "            console.print(f\"‚úÖ [bold green]New IDs added to:[/bold green] {ids_csv_path} ({len(df_nuevas_casas)} IDs)\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"‚ùå [red]Error saving new IDs to {ids_csv_path}:[/red] {e}\")\n",
    "    else:\n",
    "        console.print(\"‚ö†Ô∏è [yellow]No data found to save.[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Enmaquetado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Load CSV file ignoring errors\n",
    "console.print(\"[cyan]üìÇ Cargando datos desde 'casas_idealista.csv'...[/cyan]\")\n",
    "try:\n",
    "    df = pd.read_csv('../data/casas_idealista.csv', encoding='utf-16', sep=';')\n",
    "    console.print(f\"‚úÖ [green]Archivo cargado correctamente con {len(df)} registros.[/green]\")\n",
    "except Exception as e:\n",
    "    console.print(f\"‚ùå [red]Error al cargar el archivo:[/red] {e}\")\n",
    "    df = pd.DataFrame()  # Create an empty DataFrame\n",
    "\n",
    "# Drop 'Titulo' column\n",
    "df = df.drop(columns=['Titulo'], errors='ignore')\n",
    "\n",
    "# Drop rows with NaN in any column\n",
    "df_limpio = df.dropna()\n",
    "\n",
    "console.print(f\"üîç [yellow]Registros despu√©s de eliminar filas con NaN:[/yellow] {len(df_limpio)}\")\n",
    "\n",
    "# Function to extract square meters\n",
    "def extraer_m2(texto):\n",
    "    match_construidos = re.search(r'(\\d+)\\s*m¬≤ construidos', texto)\n",
    "    match_utiles = re.search(r'(\\d+)\\s*m¬≤ √∫tiles', texto)\n",
    "    return int(match_construidos.group(1)) if match_construidos else None, \\\n",
    "           int(match_utiles.group(1)) if match_utiles else None\n",
    "\n",
    "# Apply extraction of square meters\n",
    "df[['m2_construidos', 'm2_utiles']] = df['Caracteristicas_basicas'].apply(lambda x: pd.Series(extraer_m2(str(x))))\n",
    "\n",
    "console.print(\"üè† [cyan]Metros cuadrados extra√≠dos correctamente.[/cyan]\")\n",
    "\n",
    "# Extract bedrooms and bathrooms\n",
    "def extraer_habitaciones_banos(texto):\n",
    "    match_habitaciones = re.search(r'(\\d+)\\s*habitaci[o√≥]n(?:es)?', texto)\n",
    "    match_banos = re.search(r'(\\d+)\\s*ba√±(?:o|os)', texto)\n",
    "    return int(match_habitaciones.group(1)) if match_habitaciones else None, \\\n",
    "           int(match_banos.group(1)) if match_banos else None\n",
    "\n",
    "df[['habitaciones', 'banos']] = df['Caracteristicas_basicas'].apply(lambda x: pd.Series(extraer_habitaciones_banos(str(x))))\n",
    "\n",
    "console.print(\"üõèÔ∏è [cyan]Habitaciones y ba√±os extra√≠dos correctamente.[/cyan]\")\n",
    "\n",
    "# Extract property condition\n",
    "def extraer_estado_vivienda(texto):\n",
    "    texto = texto.lower()\n",
    "    if \"segunda mano/buen estado\" in texto:\n",
    "        return \"Segunda mano/Buen estado\"\n",
    "    elif \"segunda mano/para reformar\" in texto:\n",
    "        return \"Segunda mano/Para reformar\"\n",
    "    elif \"promoci√≥n de obra nueva\" in texto:\n",
    "        return \"Obra nueva\"\n",
    "    return None\n",
    "\n",
    "# Detect if it is exterior or interior as binary variables\n",
    "df['Exterior'] = df['Caracteristicas_basicas'].apply(\n",
    "    lambda x: 1 if isinstance(x, str) and 'exterior' in x.lower() else 0\n",
    ")\n",
    "\n",
    "df['Interior'] = df['Caracteristicas_basicas'].apply(\n",
    "    lambda x: 1 if isinstance(x, str) and 'interior' in x.lower() else 0\n",
    ")\n",
    "\n",
    "df['estado_vivienda'] = df['Caracteristicas_basicas'].apply(lambda x: extraer_estado_vivienda(str(x)))\n",
    "\n",
    "console.print(\"üèöÔ∏è [cyan]Estado de la vivienda extra√≠do correctamente.[/cyan]\")\n",
    "\n",
    "# Create binary variables for features\n",
    "caracteristicas = {\n",
    "    \"trastero\": \"Trastero\",\n",
    "    \"terraza\": \"Terraza\",\n",
    "    \"balcon\": \"Balc√≥n\",\n",
    "    \"ascensor\": \"con ascensor\",\n",
    "    \"armarios_empotrados\": \"armarios empotrados\",\n",
    "    \"plaza_garaje\": \"garaje\",\n",
    "    \"garaje_incluido\": \"incluida\",\n",
    "    \"garaje_adicional\": \"adicionales\",\n",
    "    \"adaptado_movilidad_reducida\": \"movilidad reducida\"\n",
    "}\n",
    "\n",
    "for col, keyword in caracteristicas.items():\n",
    "    df[col] = df['Caracteristicas_basicas'].apply(lambda x: 1 if isinstance(x, str) and keyword.lower() in x.lower() else 0)\n",
    "\n",
    "console.print(\"‚úÖ [green]Variables binarias extra√≠das correctamente.[/green]\")\n",
    "\n",
    "# Extract orientations\n",
    "def detectar_orientaciones(texto):\n",
    "    orientaciones = {'orientacion_este': 0, 'orientacion_oeste': 0, 'orientacion_norte': 0, 'orientacion_sur': 0}\n",
    "    if pd.isna(texto):\n",
    "        return orientaciones\n",
    "    texto = texto.lower()\n",
    "    for orientacion in orientaciones.keys():\n",
    "        if orientacion.replace('orientacion_', '') in texto:\n",
    "            orientaciones[orientacion] = 1\n",
    "    return orientaciones\n",
    "\n",
    "orientaciones_df = df['Caracteristicas_basicas'].apply(detectar_orientaciones).apply(pd.Series)\n",
    "df = pd.concat([df, orientaciones_df], axis=1)\n",
    "\n",
    "console.print(\"üß≠ [cyan]Orientaciones extra√≠das correctamente.[/cyan]\")\n",
    "\n",
    "# Extract heating\n",
    "df['Calefacci√≥n'] = df['Caracteristicas_basicas'].str.extract(r'Calefacci√≥n ([^;]+)').fillna('sin calefacci√≥n').astype('category')\n",
    "\n",
    "# Extract year of construction\n",
    "def extraer_ano_construccion(texto):\n",
    "    match = re.search(r'construido en\\s*(\\d+)', texto.lower())\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "df['ano_construccion'] = df['Caracteristicas_basicas'].apply(lambda x: extraer_ano_construccion(str(x))).astype('Int64')\n",
    "\n",
    "# Use regex to extract the number following the word \"Planta\"\n",
    "df['planta_numero'] = df['Caracteristicas_basicas'].str.extract(r'Planta (\\d+)')\n",
    "\n",
    "# Convert the new column to a numeric type (integer)\n",
    "df['planta_numero'] = pd.to_numeric(df['planta_numero'], errors='coerce').astype('Int64')\n",
    "\n",
    "console.print(\"üèóÔ∏è [cyan]A√±o de construcci√≥n extra√≠do correctamente.[/cyan]\")\n",
    "\n",
    "# Function to detect extra features\n",
    "def extraer_caracteristicas_extras(texto):\n",
    "    # Convert text to lowercase for standardization\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Detect presence of each feature\n",
    "    jardin = 1 if 'jard√≠n' in texto else 0\n",
    "    piscina = 1 if 'piscina' in texto else 0\n",
    "    aire_acondicionado = 1 if 'aire acondicionado' in texto else 0\n",
    "    zonas_verdes = 1 if 'zonas verdes' in texto else 0\n",
    "    \n",
    "    return pd.Series([jardin, piscina, aire_acondicionado, zonas_verdes])\n",
    "\n",
    "# Apply function to 'Caracteristicas_extra' and create new columns\n",
    "df[['jardin', 'piscina', 'aire_acondicionado', 'zonas_verdes']] = df['Caracteristicas_extra'].apply(lambda x: extraer_caracteristicas_extras(str(x)))\n",
    "\n",
    "# Drop original feature columns\n",
    "df = df.drop(columns=['Caracteristicas_basicas', 'Caracteristicas_extra'], errors='ignore')\n",
    "\n",
    "# Save processed DataFrame\n",
    "output_path = '../data/casas_idealista_procesado_extra.csv'\n",
    "df.to_csv(output_path, index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "console.print(f\"üíæ [green]Datos guardados en '{output_path}'.[/green]\")\n",
    "\n",
    "# Load files to combine\n",
    "csv_file_1 = '../data/casas_idealista_procesado.csv'\n",
    "csv_file_2 = '../data/casas_idealista_procesado_extra.csv'\n",
    "output_csv_file = '../data/casas_idealista_procesado.csv'\n",
    "\n",
    "def cargar_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', sep=';')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        console.print(f\"‚ö†Ô∏è [yellow]Archivo no encontrado: {file_path}[/yellow]\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        console.print(f\"‚ùå [red]Error al leer {file_path}: {e}[/red]\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df1 = cargar_csv(csv_file_1)\n",
    "df2 = cargar_csv(csv_file_2)\n",
    "\n",
    "# Combine DataFrames\n",
    "if not df1.empty and not df2.empty:\n",
    "    df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    console.print(f\"üìä [cyan]Datos combinados: {len(df_combined)} registros.[/cyan]\")\n",
    "else:\n",
    "    if df1.empty:\n",
    "        console.print(f\"‚ö†Ô∏è [yellow]El archivo '{csv_file_1}' est√° vac√≠o.[/yellow]\")\n",
    "    if df2.empty:\n",
    "        console.print(f\"‚ö†Ô∏è [yellow]El archivo '{csv_file_2}' est√° vac√≠o.[/yellow]\")\n",
    "\n",
    "# Save combined result\n",
    "if not df_combined.empty:\n",
    "    df_combined.to_csv(output_csv_file, index=False, sep=';', encoding='utf-8')\n",
    "    console.print(f\"‚úÖ [green]Datos guardados en '{output_csv_file}'.[/green]\")\n",
    "else:\n",
    "    console.print(\"‚ùå [red]No hay datos para guardar en el archivo final.[/red]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Load CSV file ignoring errors\n",
    "console.print(\"[cyan]üìÇ Cargando datos desde 'casas_idealista.csv'...[/cyan]\")\n",
    "try:\n",
    "    df = pd.read_csv('../data/casas_idealista.csv', encoding='utf-16', sep=';')\n",
    "    console.print(f\"‚úÖ [green]Archivo cargado correctamente con {len(df)} registros.[/green]\")\n",
    "except Exception as e:\n",
    "    console.print(f\"‚ùå [red]Error al cargar el archivo:[/red] {e}\")\n",
    "    df = pd.DataFrame()  # Create an empty DataFrame\n",
    "\n",
    "# Drop 'Titulo' column\n",
    "df = df.drop(columns=['Titulo'], errors='ignore')\n",
    "\n",
    "# Drop rows with NaN in any column\n",
    "df_limpio = df.dropna()\n",
    "\n",
    "console.print(f\"üîç [yellow]Registros despu√©s de eliminar filas con NaN:[/yellow] {len(df_limpio)}\")\n",
    "\n",
    "# Function to extract square meters\n",
    "def extraer_m2(texto):\n",
    "    match_construidos = re.search(r'(\\d+)\\s*m¬≤ construidos', texto)\n",
    "    match_utiles = re.search(r'(\\d+)\\s*m¬≤ √∫tiles', texto)\n",
    "    return int(match_construidos.group(1)) if match_construidos else None, \\\n",
    "           int(match_utiles.group(1)) if match_utiles else None\n",
    "\n",
    "# Apply extraction of square meters\n",
    "df[['m2_construidos', 'm2_utiles']] = df['Caracteristicas_basicas'].apply(lambda x: pd.Series(extraer_m2(str(x))))\n",
    "\n",
    "console.print(\"üè† [cyan]Metros cuadrados extra√≠dos correctamente.[/cyan]\")\n",
    "\n",
    "# Extract bedrooms and bathrooms\n",
    "def extraer_habitaciones_banos(texto):\n",
    "    match_habitaciones = re.search(r'(\\d+)\\s*habitaci[o√≥]n(?:es)?', texto)\n",
    "    match_banos = re.search(r'(\\d+)\\s*ba√±(?:o|os)', texto)\n",
    "    return int(match_habitaciones.group(1)) if match_habitaciones else None, \\\n",
    "           int(match_banos.group(1)) if match_banos else None\n",
    "\n",
    "df[['habitaciones', 'banos']] = df['Caracteristicas_basicas'].apply(lambda x: pd.Series(extraer_habitaciones_banos(str(x))))\n",
    "\n",
    "console.print(\"üõèÔ∏è [cyan]Habitaciones y ba√±os extra√≠dos correctamente.[/cyan]\")\n",
    "\n",
    "# Extract property condition\n",
    "def extraer_estado_vivienda(texto):\n",
    "    texto = texto.lower()\n",
    "    if \"segunda mano/buen estado\" in texto:\n",
    "        return \"Segunda mano/Buen estado\"\n",
    "    elif \"segunda mano/para reformar\" in texto:\n",
    "        return \"Segunda mano/Para reformar\"\n",
    "    elif \"promoci√≥n de obra nueva\" in texto:\n",
    "        return \"Obra nueva\"\n",
    "    return None\n",
    "\n",
    "# Detect if it is exterior or interior as binary variables\n",
    "df['Exterior'] = df['Caracteristicas_basicas'].apply(\n",
    "    lambda x: 1 if isinstance(x, str) and 'exterior' in x.lower() else 0\n",
    ")\n",
    "\n",
    "df['Interior'] = df['Caracteristicas_basicas'].apply(\n",
    "    lambda x: 1 if isinstance(x, str) and 'interior' in x.lower() else 0\n",
    ")\n",
    "\n",
    "df['estado_vivienda'] = df['Caracteristicas_basicas'].apply(lambda x: extraer_estado_vivienda(str(x)))\n",
    "\n",
    "console.print(\"üèöÔ∏è [cyan]Estado de la vivienda extra√≠do correctamente.[/cyan]\")\n",
    "\n",
    "# Create binary variables for features\n",
    "caracteristicas = {\n",
    "    \"trastero\": \"Trastero\",\n",
    "    \"terraza\": \"Terraza\",\n",
    "    \"balcon\": \"Balc√≥n\",\n",
    "    \"ascensor\": \"con ascensor\",\n",
    "    \"armarios_empotrados\": \"armarios empotrados\",\n",
    "    \"plaza_garaje\": \"garaje\",\n",
    "    \"garaje_incluido\": \"incluida\",\n",
    "    \"garaje_adicional\": \"adicionales\",\n",
    "    \"adaptado_movilidad_reducida\": \"movilidad reducida\"\n",
    "}\n",
    "\n",
    "for col, keyword in caracteristicas.items():\n",
    "    df[col] = df['Caracteristicas_basicas'].apply(lambda x: 1 if isinstance(x, str) and keyword.lower() in x.lower() else 0)\n",
    "\n",
    "console.print(\"‚úÖ [green]Variables binarias extra√≠das correctamente.[/green]\")\n",
    "\n",
    "# Extract orientations\n",
    "def detectar_orientaciones(texto):\n",
    "    orientaciones = {'orientacion_este': 0, 'orientacion_oeste': 0, 'orientacion_norte': 0, 'orientacion_sur': 0}\n",
    "    if pd.isna(texto):\n",
    "        return orientaciones\n",
    "    texto = texto.lower()\n",
    "    for orientacion in orientaciones.keys():\n",
    "        if orientacion.replace('orientacion_', '') in texto:\n",
    "            orientaciones[orientacion] = 1\n",
    "    return orientaciones\n",
    "\n",
    "orientaciones_df = df['Caracteristicas_basicas'].apply(detectar_orientaciones).apply(pd.Series)\n",
    "df = pd.concat([df, orientaciones_df], axis=1)\n",
    "\n",
    "console.print(\"üß≠ [cyan]Orientaciones extra√≠das correctamente.[/cyan]\")\n",
    "\n",
    "# Extract heating\n",
    "df['Calefacci√≥n'] = df['Caracteristicas_basicas'].str.extract(r'Calefacci√≥n ([^;]+)').fillna('sin calefacci√≥n').astype('category')\n",
    "\n",
    "# Extract year of construction\n",
    "def extraer_ano_construccion(texto):\n",
    "    match = re.search(r'construido en\\s*(\\d+)', texto.lower())\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "df['ano_construccion'] = df['Caracteristicas_basicas'].apply(lambda x: extraer_ano_construccion(str(x))).astype('Int64')\n",
    "\n",
    "# Use regex to extract the number following the word \"Planta\"\n",
    "df['planta_numero'] = df['Caracteristicas_basicas'].str.extract(r'Planta (\\d+)')\n",
    "\n",
    "# Convert the new column to a numeric type (integer)\n",
    "df['planta_numero'] = pd.to_numeric(df['planta_numero'], errors='coerce').astype('Int64')\n",
    "\n",
    "console.print(\"üèóÔ∏è [cyan]A√±o de construcci√≥n extra√≠do correctamente.[/cyan]\")\n",
    "\n",
    "# Function to detect extra features\n",
    "def extraer_caracteristicas_extras(texto):\n",
    "    # Convert text to lowercase for standardization\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Detect presence of each feature\n",
    "    jardin = 1 if 'jard√≠n' in texto else 0\n",
    "    piscina = 1 if 'piscina' in texto else 0\n",
    "    aire_acondicionado = 1 if 'aire acondicionado' in texto else 0\n",
    "    zonas_verdes = 1 if 'zonas verdes' in texto else 0\n",
    "    \n",
    "    return pd.Series([jardin, piscina, aire_acondicionado, zonas_verdes])\n",
    "\n",
    "# Apply function to 'Caracteristicas_extra' and create new columns\n",
    "df[['jardin', 'piscina', 'aire_acondicionado', 'zonas_verdes']] = df['Caracteristicas_extra'].apply(lambda x: extraer_caracteristicas_extras(str(x)))\n",
    "\n",
    "# Drop original feature columns\n",
    "df = df.drop(columns=['Caracteristicas_basicas', 'Caracteristicas_extra'], errors='ignore')\n",
    "\n",
    "# Save processed DataFrame\n",
    "output_path = '../data/casas_idealista_procesado_extra.csv'\n",
    "df.to_csv(output_path, index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "console.print(f\"üíæ [green]Datos guardados en '{output_path}'.[/green]\")\n",
    "\n",
    "# Load files to combine\n",
    "csv_file_1 = '../data/casas_idealista_procesado.csv'\n",
    "csv_file_2 = '../data/casas_idealista_procesado_extra.csv'\n",
    "output_csv_file = '../data/casas_idealista_procesado.csv'\n",
    "\n",
    "def cargar_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', sep=';')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        console.print(f\"‚ö†Ô∏è [yellow]Archivo no encontrado: {file_path}[/yellow]\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        console.print(f\"‚ùå [red]Error al leer {file_path}: {e}[/red]\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df1 = cargar_csv(csv_file_1)\n",
    "df2 = cargar_csv(csv_file_2)\n",
    "\n",
    "# Combine DataFrames\n",
    "if not df1.empty and not df2.empty:\n",
    "    df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    console.print(f\"üìä [cyan]Datos combinados: {len(df_combined)} registros.[/cyan]\")\n",
    "else:\n",
    "    if df1.empty:\n",
    "        console.print(f\"‚ö†Ô∏è [yellow]El archivo '{csv_file_1}' est√° vac√≠o.[/yellow]\")\n",
    "    if df2.empty:\n",
    "        console.print(f\"‚ö†Ô∏è [yellow]El archivo '{csv_file_2}' est√° vac√≠o.[/yellow]\")\n",
    "\n",
    "# Save combined result\n",
    "if not df_combined.empty:\n",
    "    df_combined.to_csv(output_csv_file, index=False, sep=';', encoding='utf-8')\n",
    "    console.print(f\"‚úÖ [green]Datos guardados en '{output_csv_file}'.[/green]\")\n",
    "else:\n",
    "    console.print(\"‚ùå [red]No hay datos para guardar en el archivo final.[/red]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IDS = False  # Change to True to test sample IDs\n",
    "\n",
    "# üìå Define base path to save reports\n",
    "base_path = \"../reports\"\n",
    "\n",
    "# üìÇ Load the file with new property IDs\n",
    "console.print(\"[cyan]üìÇ Cargando datos desde 'casas_idealista_predicciones.csv'...[/cyan]\")\n",
    "df = pd.read_csv('../data/casas_idealista_predicciones.csv', sep=';')\n",
    "\n",
    "# Convert IDs to integers and filter new properties\n",
    "df[\"id\"] = df[\"id\"].astype(int)\n",
    "if TEST_IDS:\n",
    "    nuevos_ids = [107764183, 107763878]\n",
    "else:\n",
    "    nuevos_ids = [int(id) for id in nuevos_ids]\n",
    "nuevas_casas = df[df[\"id\"].isin(nuevos_ids)]\n",
    "\n",
    "console.print(f\"üè° [yellow]Nuevos inmuebles detectados:[/yellow] {len(nuevas_casas)}\")\n",
    "\n",
    "# üìå Apply threshold filter for weighted difference\n",
    "console.print(\"üìä [cyan]Aplicando criterios de selecci√≥n...[/cyan]\")\n",
    "\n",
    "# Define location groups\n",
    "grupo_1 = [\n",
    "    \"Actur\", \"Centro\", \"Grancasa\", \"Almozara\", \"Pol Universidad Romareda\",\n",
    "    \"Doctor Cerrada\", \"Universidad San Francisco\", \"Paseo Sagasta\",\n",
    "    \"Paseo Independencia\", \"Casco Historico\", \"Alfonso\", \"Paseo de la Constituci√≥n\"\n",
    "]\n",
    "\n",
    "grupo_2 = [\n",
    "    \"Ranillas\", \"Plaza de Toros\", \"Barrio del AVE\", \"Mercado San Valero\"\n",
    "]\n",
    "\n",
    "clientes = pd.read_csv('../data/clientes.csv', sep=';')\n",
    "\n",
    "# Calculate threshold for each property\n",
    "def calcular_umbral(row):\n",
    "    precio = row['Precio']\n",
    "    barrio = row['Localizacion']\n",
    "    umbral = 0\n",
    "    if barrio in grupo_1:\n",
    "        umbral = precio * 0.03 if 0 <= precio < 180000 else precio * 0.01 if 180000 <= precio <= 1500000 else 0\n",
    "    elif barrio in grupo_2:\n",
    "        umbral = precio * 0.05 if 0 <= precio < 150000 else precio * 0.03 if 150000 <= precio <= 1500000 else 0\n",
    "    else:\n",
    "        umbral = precio * 0.1 if 0 <= precio < 150000 else precio * 0.07 if 150000 <= precio <= 1500000 else 0\n",
    "    return max(0, umbral)  # <- ensures it is not negative\n",
    "\n",
    "nuevas_casas['Umbral'] = nuevas_casas.apply(calcular_umbral, axis=1)\n",
    "\n",
    "# üìä Apply filter by difference vs threshold\n",
    "nuevas_casas = nuevas_casas[nuevas_casas[\"Diferencia_Ponderada\"] >= nuevas_casas[\"Umbral\"]].reset_index(drop=True)\n",
    "\n",
    "# Create dictionary to map property index to list of interested clients\n",
    "interesados_por_casa = {}\n",
    "\n",
    "# Iterate over clients\n",
    "for _, cliente in clientes.iterrows():\n",
    "    # Convert values\n",
    "    barrios = [b.strip() for b in str(cliente[\"barrios_interes\"]).split(\",\") if b.strip()]\n",
    "    estados = [e.strip().lower() for e in str(cliente[\"estados_vivienda\"]).split(\",\") if e.strip()]\n",
    "    extras = [e.strip() for e in str(cliente[\"extras\"]).split(\",\") if e.strip()]\n",
    "\n",
    "    filtro = pd.Series(True, index=nuevas_casas.index)\n",
    "\n",
    "    # Price\n",
    "    if pd.notna(cliente[\"precio_min\"]):\n",
    "        filtro &= nuevas_casas[\"Precio\"] >= float(cliente[\"precio_min\"])\n",
    "    if pd.notna(cliente[\"precio_max\"]):\n",
    "        filtro &= nuevas_casas[\"Precio\"] <= float(cliente[\"precio_max\"])\n",
    "\n",
    "    # Square meters\n",
    "    if pd.notna(cliente[\"m2_min\"]):\n",
    "        filtro &= nuevas_casas[\"m2_utiles\"] >= float(cliente[\"m2_min\"])\n",
    "    if pd.notna(cliente[\"m2_max\"]):\n",
    "        filtro &= nuevas_casas[\"m2_utiles\"] <= float(cliente[\"m2_max\"])\n",
    "\n",
    "    # Floor\n",
    "    if pd.notna(cliente[\"planta_min\"]):\n",
    "        filtro &= nuevas_casas[\"planta_numero\"].fillna(-1000) >= float(cliente[\"planta_min\"])\n",
    "    if pd.notna(cliente[\"planta_max\"]):\n",
    "        filtro &= nuevas_casas[\"planta_numero\"].fillna(1000) <= float(cliente[\"planta_max\"])\n",
    "\n",
    "    # Bedrooms\n",
    "    if pd.notna(cliente[\"habitaciones_min\"]):\n",
    "        filtro &= nuevas_casas[\"habitaciones\"] >= float(cliente[\"habitaciones_min\"])\n",
    "\n",
    "    # Bathrooms\n",
    "    if pd.notna(cliente[\"ba√±os_min\"]):\n",
    "        filtro &= nuevas_casas[\"banos\"] >= float(cliente[\"ba√±os_min\"])\n",
    "\n",
    "    # Exterior\n",
    "    if pd.notna(cliente[\"exterior\"]):\n",
    "        filtro &= nuevas_casas[\"Exterior\"].astype(str).str.lower().isin([\"1\", \"true\", \"s√≠\", \"si\"])\n",
    "\n",
    "    # Neighborhoods (partial match)\n",
    "    if barrios:\n",
    "        filtro &= nuevas_casas[\"Localizacion\"].str.lower().apply(\n",
    "            lambda loc: any(barrio.lower() in loc for barrio in barrios)\n",
    "        )\n",
    "\n",
    "    # Property condition\n",
    "    if estados:\n",
    "        filtro &= nuevas_casas[\"estado_vivienda\"].str.lower().isin(estados)\n",
    "\n",
    "    # Preliminary filter applied\n",
    "    candidatas = nuevas_casas[filtro].copy()\n",
    "\n",
    "    # Extras (all desired must be active)\n",
    "    for extra in extras:\n",
    "        if extra in candidatas.columns:\n",
    "            candidatas = candidatas[candidatas[extra].fillna(0).astype(int) == 1]\n",
    "\n",
    "    # Associate client to each matching property\n",
    "    for idx in candidatas.index:\n",
    "        if idx not in interesados_por_casa:\n",
    "            interesados_por_casa[idx] = []\n",
    "        interesados_por_casa[idx].append(cliente['id'])\n",
    "\n",
    "# Add column with list of interested clients\n",
    "nuevas_casas['Clientes_Interesados'] = nuevas_casas.index.map(lambda idx: interesados_por_casa.get(idx, []))\n",
    "\n",
    "# Filter properties with at least one interested client\n",
    "notificaciones = nuevas_casas[nuevas_casas['Clientes_Interesados'].map(len) > 0].copy()\n",
    "\n",
    "if not notificaciones.empty:\n",
    "    console.print(f\"‚úÖ [green]{len(notificaciones)} inmuebles cumplen los criterios de inversi√≥n.[/green]\")\n",
    "else:\n",
    "    console.print(\"‚ö†Ô∏è [red]No hay inmuebles interesantes para generar informes. Terminando ejecuci√≥n.[/red]\")\n",
    "    exit()\n",
    "    \n",
    "\n",
    "# üìå Generate CSV with filtered properties\n",
    "notificaciones[\"Seleccionado\"] = \"No\"\n",
    "notificaciones[\"Enlace\"] = \"https://www.idealista.com/inmueble/\" + notificaciones[\"id\"].astype(str) + \"/\"\n",
    "csv_path = \"../csv/buenos.csv\"\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    os.remove(csv_path)\n",
    "notificaciones.to_csv(csv_path, index=False, sep=\";\")\n",
    "\n",
    "subprocess.run([\"open\", csv_path])  # Open file in Numbers\n",
    "\n",
    "# üìå Wait for CSV editing\n",
    "console.print(\"üïí [yellow]Esperando edici√≥n del archivo...[/yellow]\")\n",
    "last_modified = os.path.getmtime(csv_path)\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    if os.path.getmtime(csv_path) != last_modified:\n",
    "        console.print(\"‚úÖ [green]Edici√≥n detectada. Continuando ejecuci√≥n...[/green]\")\n",
    "        break\n",
    "\n",
    "# üìå Load edited CSV\n",
    "notificaciones = pd.read_csv(csv_path, sep=\";\")\n",
    "notificaciones[\"Seleccionado\"] = notificaciones[\"Seleccionado\"].astype(str).str.strip().str.lower()\n",
    "notificaciones[\"Seleccionado\"] = notificaciones[\"Seleccionado\"].isin([\"true\", \"1\", \"yes\"])\n",
    "\n",
    "# üìå Filter only selected properties\n",
    "notificaciones_marcadas = notificaciones[notificaciones[\"Seleccionado\"] == True]\n",
    "\n",
    "if not notificaciones_marcadas.empty:\n",
    "    console.print(f\"üöÄ [green]Procesando {len(notificaciones_marcadas)} pisos seleccionados...[/green]\")\n",
    "else:\n",
    "    console.print(\"‚ö†Ô∏è [red]No hay pisos seleccionados. Terminando ejecuci√≥n.[/red]\")\n",
    "    exit()\n",
    "\n",
    "# Function to start Selenium browser with anti-detection\n",
    "def iniciar_navegador():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    return uc.Chrome(\n",
    "        options=options,\n",
    "        use_subprocess=True,\n",
    "        driver_executable_path=\"/Users/andres/chromedrivers/140/chromedriver\"\n",
    "    )\n",
    "\n",
    "# Start browser\n",
    "browser = iniciar_navegador()\n",
    "\n",
    "info_dicts = {}\n",
    "\n",
    "# üìå Function to download image\n",
    "def descargar_imagen(url, file_path):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    file.write(chunk)\n",
    "            console.print(f\"‚úÖ [green]Imagen guardada en {file_path}[/green]\")\n",
    "        else:\n",
    "            console.print(f\"‚ö†Ô∏è [yellow]No se pudo descargar la imagen desde {url}[/yellow]\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"‚ö†Ô∏è [red]Error al descargar la imagen: {e}[/red]\")\n",
    "\n",
    "# List to store dictionaries for each property\n",
    "listings_data = []\n",
    "\n",
    "# üìå Scraping and chart generation\n",
    "for _, row in track(notificaciones_marcadas.iterrows(), total=len(notificaciones_marcadas), description=\"üìä Procesando informes...\"):\n",
    "    listing_id = str(row['id'])\n",
    "    url_inmueble = f\"https://www.idealista.com/inmueble/{listing_id}/\"\n",
    "    save_path = os.path.join(base_path, listing_id)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    console.print(f\"üìÇ [cyan]Guardando archivos en:[/cyan] {save_path}\")\n",
    "\n",
    "    listing = df[df['id'] == int(listing_id)]\n",
    "    if listing.empty:\n",
    "        console.print(f\"‚ö†Ô∏è [red]El inmueble con ID {listing_id} no est√° en la base de datos.[/red]\")\n",
    "        continue\n",
    "\n",
    "    # Convert row to dictionary\n",
    "    listing_dict = listing.iloc[0].to_dict()\n",
    "\n",
    "    # Scraping description and image\n",
    "    try:\n",
    "        browser.get(url_inmueble)\n",
    "        time.sleep(random.uniform(4, 6))\n",
    "        soup = bs(browser.page_source, 'lxml')\n",
    "\n",
    "        # Get description\n",
    "        descripcion = soup.find('div', {'class': 'adCommentsLanguage'})\n",
    "        descripcion = descripcion.text.strip() if descripcion else \"No disponible\"\n",
    "\n",
    "        console.print(f\"üìú [cyan]Descripci√≥n del listing {listing_id}:[/cyan] {descripcion}\")\n",
    "        listing_dict[\"descripcion\"] = descripcion\n",
    "\n",
    "        # Get cover image (not included in dictionary)\n",
    "        img_container = soup.find('picture', {'class': 'first-image'})\n",
    "        img_tag = img_container.find('img') if img_container else None\n",
    "        portada_url = img_tag['src'] if img_tag and 'src' in img_tag.attrs else None\n",
    "\n",
    "        if portada_url:\n",
    "            file_path_portada = os.path.join(save_path, f\"Portada_{listing_id}.png\")\n",
    "            descargar_imagen(portada_url, file_path_portada)\n",
    "        else:\n",
    "            console.print(f\"‚ö†Ô∏è [yellow]No se encontr√≥ imagen de portada para el listing {listing_id}[/yellow]\")\n",
    "\n",
    "        # Save dictionary in list\n",
    "        listings_data.append(listing_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"‚ö†Ô∏è [red]Error al obtener descripci√≥n o imagen del listing {listing_id}: {e}[/red]\")\n",
    "        continue\n",
    "\n",
    "browser.quit()\n",
    "console.print(\"üèÅ [bold green]Proceso completado.[/bold green] üöÄ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Informes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Function to clean text and remove accents/errors\n",
    "def limpiar_texto(texto):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFKD', texto)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "\n",
    "# üìå Load LaTeX template from file\n",
    "with open(\"../reports/plantilla_informe.tex\", \"r\", encoding=\"utf-8\") as f:\n",
    "    plantilla = f.read()\n",
    "\n",
    "# üìå Function to remove image block if cover file does not exist\n",
    "def ajustar_latex_si_no_hay_portada(tex_code, listing_id, save_path):\n",
    "    portada_path = os.path.join(save_path, f\"Portada_{listing_id}.png\")\n",
    "    if not os.path.exists(portada_path):\n",
    "        # Remove block between \\begin{tcolorbox} and \\end{tcolorbox}\n",
    "        inicio = tex_code.find(r\"\\begin{tcolorbox}\")\n",
    "        fin = tex_code.find(r\"\\end{tcolorbox}\") + len(r\"\\end{tcolorbox}\")\n",
    "        if inicio != -1 and fin != -1 and fin > inicio:\n",
    "            tex_code = tex_code[:inicio] + tex_code[fin:]\n",
    "    return tex_code\n",
    "\n",
    "def generar_tex(info):\n",
    "    estimacion = round((info[\"Precio\"] + info[\"Diferencia_Ponderada\"]) / 10000) * 10000\n",
    "    minimo = max(\n",
    "        int(10000 * ((info[\"Precio\"] + info[\"Diferencia_Ponderada\"] - 10000 - 0.66 * info[\"Diferencia_Ponderada\"]) // 10000)),\n",
    "        int(((info[\"Precio\"] + 9999) // 10000) * 10000)\n",
    "    )\n",
    "    maximo = int(10000 * ((info[\"Precio\"] + info[\"Diferencia_Ponderada\"] + 10000 - 0.66 * info[\"Diferencia_Ponderada\"]) // 10000))\n",
    "\n",
    "    # üìå Generate interval as formatted LaTeX string\n",
    "    if minimo == maximo:\n",
    "        intervalo = f\"\\\\num{{{minimo}}} ‚Ç¨\"\n",
    "    else:\n",
    "        intervalo = f\"\\\\num{{{minimo}}} - \\\\num{{{maximo}}} ‚Ç¨\"\n",
    "    \n",
    "    valores = {\n",
    "        \"ID\": info[\"id\"],\n",
    "        \"LOCALIZACION\": info[\"Localizacion\"],\n",
    "        \"PRECIO\": int(info[\"Precio\"]),\n",
    "        \"M2_CONSTRUIDOS\": int(info[\"m2_construidos\"]),\n",
    "        \"M2_UTIL\": int(info[\"m2_utiles\"]),\n",
    "        \"HABITACIONES\": int(info[\"habitaciones\"]),\n",
    "        \"BANOS\": int(info[\"banos\"]),\n",
    "        \"ESTADO\": info[\"estado_vivienda\"],\n",
    "        \"ASCENSOR\": \"S√≠\" if info[\"ascensor\"] else \"No\",\n",
    "        \"CALEFACCION\": info[\"Calefacci√≥n\"],\n",
    "        \"ANO\": int(info[\"ano_construccion\"]),\n",
    "        \"ESTIMACION\": estimacion,\n",
    "        \"MINIMO\": minimo,\n",
    "        \"MAXIMO\": maximo,\n",
    "        \"INTERVALO\": intervalo,\n",
    "    }\n",
    "\n",
    "    tex = plantilla\n",
    "    for clave, valor in valores.items():\n",
    "        tex = tex.replace(f\"{{{{{clave}}}}}\", str(valor))\n",
    "    return tex\n",
    "\n",
    "# üìå Check if there are interesting properties\n",
    "if notificaciones_marcadas.empty:\n",
    "    console.print(\"‚ö†Ô∏è [red]No hay nuevos inmuebles interesantes para generar informes. Terminando ejecuci√≥n.[/red]\")\n",
    "    exit()\n",
    "\n",
    "# üìå Define base path to save reports\n",
    "base_path = \"../reports\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# üìå List to store generated reports\n",
    "informes_generados = []\n",
    "\n",
    "# üîπ Generate LaTeX reports for selected properties\n",
    "for i, (_, row) in enumerate(notificaciones_marcadas.iterrows()):\n",
    "    listing_id = str(row['id'])\n",
    "    save_path = os.path.join(base_path, listing_id)\n",
    "    os.makedirs(save_path, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "    file_path_tex = os.path.join(save_path, f\"informe_{listing_id}.tex\")\n",
    "    file_path_pdf = os.path.join(save_path, f\"informe_{listing_id}.pdf\")\n",
    "\n",
    "    # üîπ Get corresponding dictionary WITHOUT converting to JSON yet\n",
    "    info_df = listings_data[i]\n",
    "\n",
    "    # ‚úÖ Generate LaTeX code automatically without OpenAI\n",
    "    tex_code = generar_tex(info_df)\n",
    "\n",
    "    # üîß Remove image block if cover does not exist\n",
    "    tex_code = ajustar_latex_si_no_hay_portada(tex_code, listing_id, save_path)\n",
    "\n",
    "    # üîπ Save LaTeX code into `.tex` file\n",
    "    with open(file_path_tex, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(tex_code)\n",
    "\n",
    "    # üîπ Compile LaTeX to PDF with `pdflatex`\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"pdflatex\", \"-output-directory\", save_path, file_path_tex],\n",
    "            check=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "        console.print(f\"‚úÖ PDF generado con √©xito: {file_path_pdf}\")\n",
    "        informes_generados.append(file_path_pdf)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        console.print(f\"‚ùå Error al compilar LaTeX para {listing_id}.\")\n",
    "        console.print(f\"üîç Detalles del error:\\n{e.stderr.decode()}\")\n",
    "\n",
    "console.print(\"üèÅ [bold green]Proceso de generaci√≥n de informes completado.[/bold green] üöÄ\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LaTeX y envio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# üìå Check if there are generated reports\n",
    "if not informes_generados:\n",
    "    console.print(\"‚ö†Ô∏è [red]No hay informes generados. No se enviar√° correo.[/red]\")\n",
    "    exit()\n",
    "\n",
    "# ‚úÖ Convert string column to real lists\n",
    "notificaciones['Clientes_Interesados'] = notificaciones['Clientes_Interesados'].apply(\n",
    "    lambda x: x if isinstance(x, list) else literal_eval(x)\n",
    ")\n",
    "\n",
    "# üì¶ Build dictionary of reports by client\n",
    "informes_por_cliente = defaultdict(list)\n",
    "\n",
    "# Iterate over generated reports and match with `notificaciones`\n",
    "for file_path_pdf in informes_generados:\n",
    "    filename = os.path.basename(file_path_pdf)  # Ex: \"informe_123456.pdf\"\n",
    "    listing_id = int(filename.replace(\"informe_\", \"\").replace(\".pdf\", \"\"))\n",
    "    \n",
    "    fila = notificaciones[notificaciones['id'] == listing_id]\n",
    "\n",
    "    if not fila.empty:\n",
    "        interesados = fila.iloc[0]['Clientes_Interesados']\n",
    "        for cliente_id in interesados:\n",
    "            informes_por_cliente[str(cliente_id)].append(file_path_pdf)  # keys as str\n",
    "\n",
    "# ‚úâÔ∏è Send emails by client\n",
    "for _, cliente in clientes.iterrows():\n",
    "    cliente_id = str(cliente['id'])  # key as str\n",
    "    email_cliente = cliente['email']\n",
    "    informes_cliente = informes_por_cliente.get(cliente_id, [])\n",
    "\n",
    "    if not informes_cliente:\n",
    "        continue  # no reports for this client\n",
    "\n",
    "    msg = EmailMessage()\n",
    "    msg[\"Subject\"] = \"Informes inmobiliarios recientes - Oportunidades destacadas para ti\"\n",
    "    msg[\"From\"] = EMAIL_SENDER\n",
    "    msg[\"To\"] = email_cliente\n",
    "    msg.set_content(\n",
    "        f\"\"\"\n",
    "        Estimado/a {cliente['nombre']},\n",
    "\n",
    "        Te adjuntamos los informes m√°s recientes que cumplimentan tus preferencias de inversi√≥n. \n",
    "\n",
    "        Un cordial saludo,  \n",
    "        El equipo de Inmobil-IA-ria.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    for file_path_pdf in informes_cliente:\n",
    "        try:\n",
    "            with open(file_path_pdf, \"rb\") as f:\n",
    "                filename = os.path.basename(file_path_pdf)\n",
    "                msg.add_attachment(f.read(), maintype=\"application\", subtype=\"pdf\", filename=filename)\n",
    "            console.print(f\"üìé Informe {filename} adjuntado para {email_cliente}\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"‚ùå Error al adjuntar {filename} para {email_cliente}: {e}\")\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as server:\n",
    "            server.login(EMAIL_SENDER, EMAIL_PASSWORD)\n",
    "            server.send_message(msg)\n",
    "        console.print(f\"‚úÖ Correo enviado a {email_cliente}\")\n",
    "    except smtplib.SMTPAuthenticationError:\n",
    "        console.print(f\"‚ùå Error de autenticaci√≥n al enviar a {email_cliente}\")\n",
    "    except smtplib.SMTPException as e:\n",
    "        console.print(f\"‚ùå Error al enviar a {email_cliente}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ponzi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
